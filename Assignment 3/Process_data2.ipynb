{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c013180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9e57587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of file paths for text files\n",
    "path = \"/Users/lejeuje/Desktop/Spark/spark/notebooks/test data\"\n",
    "text_file_paths = [\n",
    "    os.path.join(root, name)\n",
    "    for root, dirs, files in os.walk(path)\n",
    "    for name in files\n",
    "    if name.endswith('.json')\n",
    "    and not name.endswith('_SUCCESS.json')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d5695ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          aid                                              title  \\\n",
      "0    39958495  Show HN: A Postgres extension to save you from...   \n",
      "1    39958152  ChatGPT might get its own dedicated personal A...   \n",
      "2    39959354  AI meets next-gen info stealers in social medi...   \n",
      "3    39959732                                The Loneliness Cure   \n",
      "4    39958129  Do people generally agree with Shaoshan Liu an...   \n",
      "..        ...                                                ...   \n",
      "351  39959583   Newly launched unified AI assistants open source   \n",
      "352  39957731                                  Nix – A One Pager   \n",
      "353  39958350           America's Next Soldiers Will Be Machines   \n",
      "354  39959997  Freak winds kill three people by sucking them ...   \n",
      "355  39958129  Do people generally agree with Shaoshan Liu an...   \n",
      "\n",
      "                                                   url              domain  \\\n",
      "0                 https://github.com/viggy28/pg_savior  github.com/viggy28   \n",
      "1    https://www.techradar.com/computing/artificial...       techradar.com   \n",
      "2    https://www.bitdefender.com/blog/labs/ai-meets...     bitdefender.com   \n",
      "3    https://www.ft.com/content/ae99e1d7-d72a-48fc-...              ft.com   \n",
      "4    https://cacm.acm.org/blogcacm/building-computi...             acm.org   \n",
      "..                                                 ...                 ...   \n",
      "351       https://github.com/Oseni03/Unified-AI-Assist  github.com/oseni03   \n",
      "352  https://github.com/tazjin/nix-1p/blob/master/R...   github.com/tazjin   \n",
      "353  https://foreignpolicy.com/2024/04/06/us-army-m...   foreignpolicy.com   \n",
      "354  https://www.cnn.com/2024/04/05/asia/three-kill...             cnn.com   \n",
      "355  https://cacm.acm.org/blogcacm/building-computi...             acm.org   \n",
      "\n",
      "     votes             user            posted_at  comments  \\\n",
      "0        2           vira28  2024-04-07 06:01:49         0   \n",
      "1        7         cpeterso  2024-04-07 04:14:53         0   \n",
      "2        1            croes  2024-04-07 08:48:23         0   \n",
      "3        1           marban  2024-04-07 10:10:08         0   \n",
      "4        1        omnifidus  2024-04-07 04:07:32         0   \n",
      "..     ...              ...                  ...       ...   \n",
      "351      2          Oseni03  2024-04-07 09:30:48         0   \n",
      "352      3  peter_d_sherman  2024-04-07 02:44:42         0   \n",
      "353      1           jdmark  2024-04-07 05:19:50         0   \n",
      "354      4       keepamovin  2024-04-07 11:06:54         0   \n",
      "355      1        omnifidus  2024-04-07 04:07:32         0   \n",
      "\n",
      "                                          source_title  \\\n",
      "0    GitHub - viggy28/pg_savior: A postgres extensi...   \n",
      "1    ChatGPT might get its own dedicated personal A...   \n",
      "2    AI meets next-gen info stealers in social medi...   \n",
      "3                                                 None   \n",
      "4    Building Computing Systems for Embodied Artifi...   \n",
      "..                                                 ...   \n",
      "351                 GitHub - Oseni03/Unified-AI-Assist   \n",
      "352         nix-1p/README.md at master · tazjin/nix-1p   \n",
      "353           America’s Next Soldiers Will Be Machines   \n",
      "354                                    edition.cnn.com   \n",
      "355  Building Computing Systems for Embodied Artifi...   \n",
      "\n",
      "                                           source_text  frontpage  \n",
      "0    GitHub - viggy28/pg_savior: A postgres extensi...      False  \n",
      "1    ChatGPT might get its own dedicated personal A...       True  \n",
      "2    AI meets next-gen info stealers in social medi...      False  \n",
      "3    The loneliness cure\\n\\nAccessibility helpSkip ...      False  \n",
      "4    Building Computing Systems for Embodied Artifi...      False  \n",
      "..                                                 ...        ...  \n",
      "351  GitHub - Oseni03/Unified-AI-Assist\\n\\nSkip to ...      False  \n",
      "352  nix-1p/README.md at master · tazjin/nix-1p · G...       True  \n",
      "353  U.S. Army Tests Robots for Future Combat\\n\\nBy...      False  \n",
      "354  edition.cnn.com\\n\\n# This edition.cnn.com page...       True  \n",
      "355  Building Computing Systems for Embodied Artifi...      False  \n",
      "\n",
      "[356 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "def process_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        try:\n",
    "            # Load the JSON data and handle potential errors\n",
    "            json_data = json.load(f)\n",
    "            value_dict = json.loads(json_data['value'])\n",
    "\n",
    "            # Create a dictionary with the extracted values\n",
    "            data_dict = {\n",
    "                \"aid\": value_dict[\"aid\"],\n",
    "                \"title\": value_dict[\"title\"],\n",
    "                \"url\": value_dict[\"url\"],\n",
    "                \"domain\": value_dict[\"domain\"],\n",
    "                \"votes\": value_dict[\"votes\"],\n",
    "                \"user\": value_dict[\"user\"],\n",
    "                \"posted_at\": value_dict[\"posted_at\"],\n",
    "                \"comments\": value_dict[\"comments\"],\n",
    "                \"source_title\": value_dict[\"source_title\"],\n",
    "                \"source_text\": value_dict[\"source_text\"],\n",
    "                \"frontpage\": value_dict[\"frontpage\"]\n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the data list\n",
    "            data.append(data_dict)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON file '{filename}': {e}\")\n",
    "\n",
    "# Process each JSON file\n",
    "for filename in text_file_paths:\n",
    "    process_json(filename)\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "df.to_csv('reviews150.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "afb98794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cd7d9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Deep_learning_txt\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "# Remove duplicate row\n",
    "sdf = spark.createDataFrame(df)\n",
    "sdf=sdf.dropna()\n",
    "sdf = sdf.withColumn(\"frontpage\", col(\"frontpage\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fb9884b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontpage: True 44\n",
      "Frontpage: False  300\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = sdf.randomSplit([0.8, 0.2], seed=123)\n",
    "print(\"Frontpage: True\", train_data.filter(col(\"frontpage\") == True).count()+test_data.filter(col(\"frontpage\") == True).count())\n",
    "print(\"Frontpage: False \", train_data.filter(col(\"frontpage\") == False).count()+test_data.filter(col(\"frontpage\") == False).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3fc15fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn(\"frontpage\", col(\"frontpage\").cast(\"integer\"))\n",
    "# preprocess the data\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\", locale=\"en_US\")\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "#string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "\n",
    "# create model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"frontpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3d7bc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid to optimise hper parameters\n",
    "param_grid = ParamGridBuilder() \\\n",
    "   .addGrid(count_vectorizer.vocabSize, [1000, 5000]) \\\n",
    "   .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "   .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "   .build()\n",
    "\n",
    "# define the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"frontpage\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7307d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, count_vectorizer, idf, lr])\n",
    "\n",
    "# define the cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# fit pipeline to the training data\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "db0c78d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852210781344639\n"
     ]
    }
   ],
   "source": [
    "eval = MulticlassClassificationEvaluator(labelCol=\"frontpage\", predictionCol=\"prediction\")\n",
    "accuracy = eval.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "43d15709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model\n",
    "model = cv_model.bestModel\n",
    "model.save(\"model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34909dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
