{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24eccf20-3fc0-4464-9da8-a77af2d88429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from datetime import datetime\n",
    "\n",
    "#Get the data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a338d4b-4718-4541-ade1-a436b9d5420a",
   "metadata": {},
   "source": [
    "<h4>Create Days Since connected Column</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1f3ad0-c17a-4d3d-8901-cf41fd19dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = pd.to_datetime(df[\"Connect_Date\"], format = '%d/%m/%y')\n",
    "date_col.astype('int64')\n",
    "df[\"today\"] = pd.Timestamp.today()\n",
    "df[\"Days_since_connected\"] = df[\"today\"]-date_col\n",
    "df[\"Days_since_connected\"] = df[\"Days_since_connected\"].dt.days\n",
    "df.drop([\"today\", \"Connect_Date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387e82d2-6535-46ec-809f-c25ccc04dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove id\n",
    "df.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7664b15-09cb-4d5f-9c26-730944f644e7",
   "metadata": {},
   "source": [
    "<h4>Create continuous and categorical columns</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee450ca-a1d4-45bf-8887-f7063d302ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous=df._get_numeric_data().columns.tolist()\n",
    "continuous.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f99eced-efe6-40b2-bda5-c3d21c818f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=df.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fd9b1-30c8-4b91-bce1-17fb300edf21",
   "metadata": {},
   "source": [
    "<h4> Create test and training sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede589d1-bdc3-426c-9eb7-b76b96f322fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['target']\n",
    "X = df.drop(['target'], axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769a7bb-387b-4204-b916-6d41760c6029",
   "metadata": {},
   "source": [
    "<h4> Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379a5846-4c9d-427b-b4b1-91fce416b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Save untransformed data for later\n",
    "X_train_raw = X_train.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "\n",
    "#IDEA TO TRY: Sample only those above a certain threshhold\n",
    "# Tested several values and doesn't seem to have a huge impact\n",
    "# = np.median(X_train_raw[\"average cost min\"])\n",
    "#ind = X_train_raw[\"average cost min\"] >= 0.1\n",
    "#X_train = X_train_raw[ind]\n",
    "#y_train = y_train[ind]\n",
    "\n",
    "\n",
    "cts_pipe = Pipeline([\n",
    "    ('ImputeContinuous', SimpleImputer(strategy=\"median\")),\n",
    "    ('StandardScaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('ImputeCategorical', SimpleImputer(strategy = \"most_frequent\")),\n",
    "    ('OneHot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "t = ColumnTransformer(\n",
    "    [\n",
    "    (\"cts\", cts_pipe, continuous),\n",
    "    (\"cat\", cat_pipe, categorical)\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train = t.fit_transform(X_train)\n",
    "X_test=t.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6199947-b32a-40e4-ac38-4dc1c90111f9",
   "metadata": {},
   "source": [
    "<h4>Function to compute top 20 Metric</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8752a988-c0c7-47b1-a683-c10c98d0c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calculates the sum of avg_cost_min with the highest predicted probabilities\n",
    "#prediction is the predicted probabilities from the model.\n",
    "#The argument testSet should be the unstandardized testset\n",
    "def avgCostSum(prediction, y_testSet, X_testSet):\n",
    "    #Get an array of sorted predictions in descending order\n",
    "    index = np.argsort(prediction)[::-1]\n",
    "    #Select the sorted avg_cost_min column from the unstandardized dataframe, then get the 20 highest\n",
    "    avg_cost_min = X_testSet.iloc[index,].join(y_testSet.iloc[index])\n",
    "    avg_cost_min = avg_cost_min[[\"average cost min\", \"target\"]][0:20]\n",
    "    #Return the sum of the top 20 for those that were correctly predicted\n",
    "    return avg_cost_min[avg_cost_min[\"target\"]==1][\"average cost min\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3658f9-c2cd-4c51-b123-9901f71a639b",
   "metadata": {},
   "source": [
    "<h4> Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69987fb2-2791-47e0-a0cb-3d8d9b10965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------AUC----------Top20\n",
      "LRW:    0.930947    3.849698\n",
      "LR:    0.923934    3.592699\n",
      "RF:    0.933564    2.704097\n",
      "KNN:    0.734829    3.372555\n",
      "GB:    0.935432    3.332212\n"
     ]
    }
   ],
   "source": [
    "#My version test\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = []\n",
    "models.append(('LRW', LogisticRegression(solver='lbfgs', max_iter=1000, class_weight=\"balanced\")))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=1000)))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print(\"---------AUC----------Top20\")\n",
    "scoring = 'roc_auc'\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    top20 = avgCostSum(y_pred, y_test, X_test_raw)\n",
    "    results.append(auc)\n",
    "    names.append(name)\n",
    "    \n",
    "    msg = \"%s:    %f    %f\" % (name, auc, top20)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca80e83-b4e8-4dbd-9405-7e30be212110",
   "metadata": {},
   "source": [
    "<h4> Try oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24df6a2-b462-480d-bb86-84d4169b50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.75, random_state=12)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea85b587-635e-4198-8f6a-2ed80c95cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------AUC----------Top20\n",
      "LRW:    0.927345    3.844354\n",
      "LR:    0.926638    3.676723\n",
      "RF:    0.932116    2.553955\n",
      "KNN:    0.758232    1.832525\n",
      "GB:    0.939042    2.713042\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LRW', LogisticRegression(solver='lbfgs', max_iter=1000, class_weight=\"balanced\")))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=1000)))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print(\"---------AUC----------Top20\")\n",
    "scoring = 'roc_auc'\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    top20 = avgCostSum(y_pred, y_test, X_test_raw)\n",
    "    results.append(auc)\n",
    "    names.append(name)\n",
    "    msg = \"%s:    %f    %f\" % (name, auc, top20)\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
