{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24eccf20-3fc0-4464-9da8-a77af2d88429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from datetime import datetime\n",
    "\n",
    "#Get the data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a338d4b-4718-4541-ade1-a436b9d5420a",
   "metadata": {},
   "source": [
    "<h4>Create Days Since connected Column</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1f3ad0-c17a-4d3d-8901-cf41fd19dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = pd.to_datetime(df[\"Connect_Date\"], format = '%d/%m/%y')\n",
    "date_col.astype('int64')\n",
    "df[\"today\"] = pd.Timestamp.today()\n",
    "df[\"Days_since_connected\"] = df[\"today\"]-date_col\n",
    "df[\"Days_since_connected\"] = df[\"Days_since_connected\"].dt.days\n",
    "df.drop([\"today\", \"Connect_Date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387e82d2-6535-46ec-809f-c25ccc04dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove id\n",
    "df.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7664b15-09cb-4d5f-9c26-730944f644e7",
   "metadata": {},
   "source": [
    "<h4>Create continuous and categorical columns</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee450ca-a1d4-45bf-8887-f7063d302ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous=df._get_numeric_data().columns.tolist()\n",
    "continuous.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f99eced-efe6-40b2-bda5-c3d21c818f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=df.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fd9b1-30c8-4b91-bce1-17fb300edf21",
   "metadata": {},
   "source": [
    "<h4> Create test and training sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede589d1-bdc3-426c-9eb7-b76b96f322fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['target']\n",
    "X = df.drop(['target'], axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769a7bb-387b-4204-b916-6d41760c6029",
   "metadata": {},
   "source": [
    "<h4> Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379a5846-4c9d-427b-b4b1-91fce416b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "#IDEA TO TRY: Sample only those above a certain threshhold\n",
    "#ind = X_train[\"average cost min\"] >= 0.134453\n",
    "#X_train = X_train[ind]\n",
    "#y_train = y_train[ind]\n",
    "\n",
    "\n",
    "#Save untransformed data for later\n",
    "X_train_raw = X_train.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "#Cotinuous Transformations\n",
    "cts_pipe = Pipeline([\n",
    "    ('ImputeContinuous', SimpleImputer(strategy=\"median\")),\n",
    "    ('StandardScaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "#Categorical Transformations\n",
    "cat_pipe = Pipeline([\n",
    "    ('OneHot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "#Apply to columns\n",
    "t = ColumnTransformer(\n",
    "    [\n",
    "    (\"cts\", cts_pipe, continuous),\n",
    "    (\"cat\", cat_pipe, categorical)\n",
    "    ])\n",
    "\n",
    "# All trasnformations. Add any here that would apply to both continuous and categorical\n",
    "final_pipeline = Pipeline([\n",
    "    ('columns', t),\n",
    "    #('PCA', PCA())\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train = final_pipeline.fit_transform(X_train)\n",
    "X_test= final_pipeline.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6199947-b32a-40e4-ac38-4dc1c90111f9",
   "metadata": {},
   "source": [
    "<h4>Function to compute top 20 Metric</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8752a988-c0c7-47b1-a683-c10c98d0c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calculates the sum of avg_cost_min with the highest predicted probabilities\n",
    "#prediction is the predicted probabilities from the model.\n",
    "#The argument testSet should be the unstandardized testset\n",
    "def avgCostSum(prediction, y_testSet, X_testSet):\n",
    "    #Get an array of sorted predictions in descending order\n",
    "    index = np.argsort(prediction)[::-1]\n",
    "    #Select the sorted avg_cost_min column from the unstandardized dataframe, then get the 20 highest\n",
    "    avg_cost_min = X_testSet.iloc[index,].join(y_testSet.iloc[index])\n",
    "    avg_cost_min = avg_cost_min[[\"average cost min\", \"target\"]][0:20]\n",
    "    #Return the sum of the top 20 for those that were correctly predicted\n",
    "    return avg_cost_min[avg_cost_min[\"target\"]==1][\"average cost min\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3658f9-c2cd-4c51-b123-9901f71a639b",
   "metadata": {},
   "source": [
    "<h4> Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69987fb2-2791-47e0-a0cb-3d8d9b10965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------AUC----------Top20------Accuracy----Precision----Recall\n",
      "LR  :    0.917071    3.264576    0.921705    0.756944    0.712418\n",
      "LRW :    0.921821    3.161221    0.913776    0.679348    0.816993\n",
      "RF  :    0.918900    2.652866    0.915758    0.746377    0.673203\n",
      "KNN :    0.747240    3.060730    0.863231    0.641509    0.222222\n",
      "GB  :    0.935870    2.428153    0.915758    0.739437    0.686275\n",
      "XGB :    0.940115    2.429886    0.920714    0.748299    0.718954\n",
      "XGBW:    0.940375    2.190504    0.921705    0.734177    0.758170\n"
     ]
    }
   ],
   "source": [
    "#My version test\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "models = []\n",
    "models.append(('LR  ', LogisticRegression(solver='lbfgs', max_iter=1000)))\n",
    "models.append(('LRW ', LogisticRegression(solver='lbfgs', max_iter=1000, class_weight=\"balanced\")))\n",
    "models.append(('RF  ', RandomForestClassifier()))\n",
    "models.append(('KNN ', KNeighborsClassifier()))\n",
    "models.append(('GB  ', GradientBoostingClassifier()))\n",
    "models.append(('XGB ', XGBClassifier()))\n",
    "models.append(('XGBW', XGBClassifier(scale_pos_weight=5)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print(\"---------AUC----------Top20------Accuracy----Precision----Recall\")\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    cat_preds = [round(value) for value in y_pred]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, cat_preds)\n",
    "    precision = precision_score(y_test,cat_preds)\n",
    "    recall = recall_score(y_test,cat_preds)\n",
    "    top20 = avgCostSum(y_pred, y_test, X_test_raw)\n",
    "    results.append(auc)\n",
    "    names.append(name)\n",
    "    \n",
    "    msg = \"%s:    %f    %f    %f    %f    %f\" % (name, auc, top20, accuracy, precision, recall)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca80e83-b4e8-4dbd-9405-7e30be212110",
   "metadata": {},
   "source": [
    "<h4> Try oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24df6a2-b462-480d-bb86-84d4169b50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.5,random_state=42)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea85b587-635e-4198-8f6a-2ed80c95cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------AUC----------Top20------Accuracy----Precision----Recall\n",
      "LR  :    0.922073    3.371483    0.922696    0.730061    0.777778\n",
      "LRW :    0.923340    3.371483    0.914767    0.687151    0.803922\n",
      "RF  :    0.920912    2.381582    0.921705    0.750000    0.725490\n",
      "KNN :    0.760728    3.125176    0.802775    0.392523    0.549020\n",
      "GB  :    0.934969    2.616514    0.922696    0.741935    0.751634\n",
      "XGB :    0.936511    2.609524    0.917740    0.743056    0.699346\n",
      "XGBW:    0.935213    2.435331    0.927651    0.743902    0.797386\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "print(\"---------AUC----------Top20------Accuracy----Precision----Recall\")\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    cat_preds = [round(value) for value in y_pred]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, cat_preds)\n",
    "    precision = precision_score(y_test,cat_preds)\n",
    "    recall = recall_score(y_test,cat_preds)\n",
    "    top20 = avgCostSum(y_pred, y_test, X_test_raw)\n",
    "    results.append(auc)\n",
    "    names.append(name)\n",
    "    \n",
    "    msg = \"%s:    %f    %f    %f    %f    %f\" % (name, auc, top20, accuracy, precision, recall)\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
